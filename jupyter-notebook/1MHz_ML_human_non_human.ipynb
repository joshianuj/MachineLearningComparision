{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car:  5851\n",
      "Wall:  5456\n",
      "Pillar:  5772\n",
      "Human:  3700\n",
      "Total data:  20779\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xlrd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.fft import fft, fftfreq\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split(X_, index):\n",
    "    y_ = [index]*len(X_)\n",
    "    return train_test_split(X_, y_, test_size=0.40, random_state=42)\n",
    "\n",
    "import glob\n",
    "\n",
    "def get_fft_set(file_names):\n",
    "    fft_set = []\n",
    "    for files in file_names:\n",
    "        data = pd.read_csv(files)\n",
    "        fft_data = fft_from_data_frame(data)\n",
    "        fft_set = fft_data + fft_set\n",
    "    return fft_set\n",
    "\n",
    "def fft_from_data_frame(data_frame):\n",
    "    fs= 1.14e6\n",
    "    signal_set = []\n",
    "    nan_indexes = np.where(np.any(np.isnan(data_frame.values), axis=1))\n",
    "    data_frame_values = np.delete(data_frame.values, nan_indexes, axis=0)\n",
    "    for row in data_frame_values:\n",
    "        fft_data = fft(row, n=row.size)/row.size\n",
    "        freq = fftfreq(row.size, d=1/fs)\n",
    "        cut_high_signal = abs(fft_data).copy()\n",
    "        cut_high_signal[(freq > 50000)] = 0\n",
    "        cut_high_signal[(freq < 30000)] = 0\n",
    "        signal_without_0 = list(filter(lambda a: a != 0, cut_high_signal))\n",
    "        signal_set.append(np.abs(signal_without_0))\n",
    "    return signal_set\n",
    "\n",
    "car_side = glob.glob('../data/1mhz_data/result/26_Ford_Black_side/*_overall.csv')\n",
    "wall = glob.glob('../data/1mhz_data/result/Wall/*_overall.csv')\n",
    "pillar = glob.glob('../data/1mhz_data/result/Pillar/*_overall.csv')\n",
    "human = glob.glob('../data/1mhz_data/result/Human/*_overall.csv')\n",
    "\n",
    "car_side_fft = get_fft_set(car_side)\n",
    "wall_fft = get_fft_set(wall)\n",
    "pillar_fft = get_fft_set(pillar)\n",
    "human_fft = get_fft_set(human)\n",
    "\n",
    "print(\"Car: \", len(car_side_fft))\n",
    "print(\"Wall: \", len(wall_fft))\n",
    "print(\"Pillar: \", len(pillar_fft))\n",
    "print(\"Human: \", len(human_fft))\n",
    "\n",
    "result = len(car_side_fft) + len(wall_fft) + len(pillar_fft) + len(human_fft)\n",
    "print(\"Total data: \", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2220, 36) (1480, 36) (2220,) (1480,)\n"
     ]
    }
   ],
   "source": [
    "human = human_fft\n",
    "X_Human_train, X_Human_test, y_Human_train, y_Human_test = split(human, 'HUMAN')\n",
    "\n",
    "Non_Human = car_side_fft + wall_fft + pillar_fft\n",
    "X_Non_Human_train, X_Non_Human_test, y_Non_Human_train, y_Non_Human_test = split(Non_Human, 'NOT HUMAN')\n",
    "\n",
    "X_Human_Non_Human_train = X_Human_train + X_Non_Human_train\n",
    "# X_Human_Non_Human_test = np.nan_to_num(X_Human_test + X_Non_Human_test)\n",
    "X_Human_Non_Human_test = (X_Human_test + X_Non_Human_test)\n",
    "\n",
    "y_Human_Non_Human_train = y_Human_train + y_Non_Human_train\n",
    "y_Human_Non_Human_test = y_Human_test + y_Non_Human_test\n",
    "\n",
    "# np.nan_to_num(X)\n",
    "\n",
    "print(np.array(X_Human_train).shape,np.array(X_Human_test).shape, np.array(y_Human_train).shape, np.array(y_Human_test).shape)\n",
    "# print(np.array(X_Non_Human_train).shape, np.array(X_Non_Human_test).shape, np.array(y_Non_Human_train).shape, np.array(y_Non_Human_test).shape)\n",
    "# print(len(X_Human_Non_Human_train))\n",
    "# print(len(X_Human_Non_Human_test))\n",
    "# print(len(y_Human_Non_Human_train))\n",
    "# print(len(y_Human_Non_Human_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train data :  (12467, 36)\n",
      "y train data :  (12467,)\n",
      "X test data :  (8312, 36)\n",
      "y test data :  (8312,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "def custom_normalization(X_set):\n",
    "    new_X_set = []\n",
    "    for X in X_set:\n",
    "        min = np.min(X)\n",
    "        max = np.max(X)\n",
    "        value = max - min\n",
    "        data_set = []\n",
    "        for data in X:\n",
    "           data_set.append(((data - min) / value) + 0)\n",
    "        new_X_set.append(data_set)\n",
    "    return new_X_set\n",
    "\n",
    "normalized_X_Human_Non_Human_train = custom_normalization(X_Human_Non_Human_train)\n",
    "normalized_X_Human_Non_Human_test = custom_normalization(X_Human_Non_Human_test)\n",
    "\n",
    "\n",
    "print('X train data : ',np.array(X_Human_Non_Human_train).shape)\n",
    "print('y train data : ',np.array(y_Human_Non_Human_train).shape)\n",
    "print('X test data : ',np.array(X_Human_Non_Human_test).shape)\n",
    "print('y test data : ',np.array(y_Human_Non_Human_test).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "def create_confusion_matrix(y_test, result):\n",
    "    cm = confusion_matrix(y_test, result)\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt     \n",
    "    sum = np.sum(cm, axis=1)\n",
    "    score = accuracy_score(y_test, result)\n",
    "\n",
    "    from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "    precision_CLASS_A = round(precision_score(y_test, result, average='binary',pos_label=labels[0]),2)\n",
    "    precision_CLASS_B = round(precision_score(y_test, result, average='binary',pos_label=labels[1]),2)\n",
    "    recall_CLASS_A = round(recall_score(y_test, result, average='binary',pos_label=labels[0]),2)\n",
    "    recall_CLASS_B = round(recall_score(y_test, result, average='binary',pos_label=labels[1]),2)\n",
    "    f1_CLASS_A = round(f1_score(y_test, result, average='binary',pos_label=labels[0]),2)\n",
    "    f1_CLASS_B = round(f1_score(y_test, result, average='binary',pos_label=labels[1]),2)\n",
    "    f1_average = round((f1_CLASS_A + f1_CLASS_B)/2, 2);\n",
    "    print('Precision: Class A',precision_CLASS_A)\n",
    "    print('Precision: Class B',precision_CLASS_B)\n",
    "#     print('Recall: Class A',recall_CLASS_A)\n",
    "#     print('Recall: Class B',recall_CLASS_B)\n",
    "#     print('F1-Score: Class A',f1_CLASS_A)\n",
    "#     print('F1-Score: Class B',f1_CLASS_B)\n",
    "#     print('Average F1-score:', f1_average)\n",
    "\n",
    "    cm_new = np.append(cm[0], recall_CLASS_A)\n",
    "    cm_new2 = np.append(cm[1], recall_CLASS_B)\n",
    "    cm_new3 = np.array([precision_CLASS_A, precision_CLASS_B, score])\n",
    "    cm = np.array([cm_new,cm_new2,cm_new3])\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    sns.heatmap(cm, annot=True, ax = ax,linewidths=.5,fmt='g',cmap=\"Reds\"); #annot=True to annotate cells\n",
    "\n",
    "    # labels, title and ticks\n",
    "    ax.set_xlabel('Predicted labels');\n",
    "    ax.set_ylabel('True labels'); \n",
    "    ax.set_title(title); \n",
    "    counter = 0\n",
    "    for i in range(0,2):\n",
    "        for j in range(0,3):\n",
    "            percentage = cm[i][j]/sum[i]\n",
    "            t = ax.texts[counter]\n",
    "            if j == 2:\n",
    "                t.set_text(str(cm[i][j]))\n",
    "            else:\n",
    "                t.set_text(str(cm[i][j]) + '\\n' + str(round(percentage*100,2)) + \" %\")\n",
    "            counter = counter + 1\n",
    "\n",
    "    ax.xaxis.set_ticklabels(labels)\n",
    "    ax.yaxis.set_ticklabels(labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden layer 1 score average 0.9057218935814876\n",
      "hidden layer 2 score average 0.9062515289634824\n",
      "hidden layer 3 score average 0.8732356933866501\n",
      "hidden layer 4 score average 0.8723691701599465\n",
      "hidden layer 5 score average 0.8254047965775619\n",
      "hidden layer 6 score average 0.8165024407902313\n",
      "hidden layer 7 score average 0.7691907645207187\n",
      "hidden layer 8 score average 0.8085553949349239\n",
      "hidden layer 9 score average 0.8027833211280274\n",
      "hidden layer 10 score average 0.8377713971408972\n",
      "hidden layer 11 score average 0.7645194402031232\n",
      "hidden layer 12 score average 0.7624069502613667\n",
      "hidden layer 13 score average 0.8160117829038812\n",
      "hidden layer 14 score average 0.8316542161706915\n",
      "hidden layer 15 score average 0.8204452055408407\n",
      "hidden layer 16 score average 0.793395247382939\n",
      "hidden layer 17 score average 0.779053043619236\n",
      "hidden layer 18 score average 0.8154409606067027\n",
      "hidden layer 19 score average 0.776453126546116\n",
      "hidden layer 20 score average 0.7732826928816657\n",
      "hidden layer 21 score average 0.791421311669016\n",
      "hidden layer 22 score average 0.7840579277565111\n",
      "hidden layer 23 score average 0.7639892142530127\n",
      "hidden layer 24 score average 0.7596619896589994\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "human_validate = custom_normalization(human)\n",
    "Non_Human_validate = custom_normalization(Non_Human)\n",
    "X_validate = Non_Human_validate + human_validate\n",
    "y_validate = ['NON_HUMAN']* len(Non_Human_validate) + ['HUMAN']* len(human_validate)\n",
    "result = []\n",
    "for i in range(1,90):\n",
    "    clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(i), random_state=12)\n",
    "    scores = cross_val_score(clf, X_validate, y_validate, cv=3, scoring=\"accuracy\")\n",
    "    result.append({\n",
    "        'neurons': i,\n",
    "        'layer': 1,\n",
    "        'score': scores.mean(),\n",
    "        'cross_fold_size': 3,\n",
    "        'random_state': 12\n",
    "    })\n",
    "    print(\"hidden layer\", i, \"score average\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cross_fold_size</th>\n",
       "      <th>layer</th>\n",
       "      <th>neurons</th>\n",
       "      <th>random_state</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0.906252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.905722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0.873236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0.872369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>0.825405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0.816502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.808555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>0.802783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0.769191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cross_fold_size  layer  neurons  random_state     score\n",
       "0                3      1        2            12  0.906252\n",
       "1                3      1        1            12  0.905722\n",
       "2                3      1        3            12  0.873236\n",
       "3                3      1        4            12  0.872369\n",
       "4                3      1        5            12  0.825405\n",
       "5                3      1        6            12  0.816502\n",
       "6                3      1        8            12  0.808555\n",
       "7                3      1        9            12  0.802783\n",
       "8                3      1        7            12  0.769191"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame(sorted(result, key=lambda x: x['score'], reverse=True))\n",
    "result_df.to_csv('../data/1mhz_data/ml_test/layer1_neurons_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
